{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA-6543 Assignment 4\n",
    "\n",
    "Jason Gillette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "(a) Explain how k-fold cross-validation is implemented.\n",
    "\n",
    "In k-fold cross-validation, the data set is randomly divided into k equal-sized folds. Chapter 5, section 1 of the text details the process as follows:\n",
    "\n",
    "    i. For each of the k iterations, one fold is set aside as the validation set, and the model is trained on the remaining k−1 folds.\n",
    "\n",
    "    ii. The model is then used to make predictions on the held-out fold, and an error is computed (e.g., MSE for regression).\n",
    "\n",
    "    iii. After all k iterations, the cross-validation error is estimated by averaging the k individual error estimates\n",
    "\n",
    "(b) What are the advantages and disadvantages of k-fold cross-validation relative to:\n",
    "    \n",
    "    i. The validation set approach?\n",
    "\n",
    "        The advantage of k-fold cross validation over traditional validation is that it uses the entire dataset for both training and validation, which provides a more stable and reliable estimate of test error. Cross validated models tend to better fit and are less prone to variability caused by training-testing split. However, the disadvantage of cross-validation is it can be more resource intensive and complex to set up, although this is increasingly abstracted by various libraries.\n",
    "    \n",
    "    ii. Leave One Out Cross Validation (LOOCV)?\n",
    "\n",
    "        The advantage of k-fold over LOOCV, is that k-fold is significantly less computationally expensive. Where k-fold may split on multiple observation (e.g. k+5, K=10), LOOCV performs a split of every single observation, training on n-1 observations for n iterations. Because the test hold-out is different across every iteration, LOOCV may also result in higher variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. \n",
    "\n",
    "In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>default</th>\n",
       "      <th>student</th>\n",
       "      <th>balance</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>729.526495</td>\n",
       "      <td>44361.625074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>817.180407</td>\n",
       "      <td>12106.134700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>1073.549164</td>\n",
       "      <td>31767.138947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>529.250605</td>\n",
       "      <td>35704.493935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>785.655883</td>\n",
       "      <td>38463.495879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  default student      balance        income\n",
       "0      No      No   729.526495  44361.625074\n",
       "1      No     Yes   817.180407  12106.134700\n",
       "2      No      No  1073.549164  31767.138947\n",
       "3      No      No   529.250605  35704.493935\n",
       "4      No      No   785.655883  38463.495879"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Default dataset\n",
    "default = load_data('Default')\n",
    "default.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5a.\n",
    "\n",
    "Fit a logistic regression model that uses income and balance to predict default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.078948\n",
      "         Iterations 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>default01</td>    <th>  No. Observations:  </th>   <td> 10000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>   <td>  9997</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>   <td>     2</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Sat, 03 May 2025</td> <th>  Pseudo R-squ.:     </th>   <td>0.4594</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>18:47:43</td>     <th>  Log-Likelihood:    </th>  <td> -789.48</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th>  <td> -1460.3</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th> <td>4.541e-292</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td></td>        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>   <td>  -11.5405</td> <td>    0.435</td> <td>  -26.544</td> <td> 0.000</td> <td>  -12.393</td> <td>  -10.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>income</th>  <td> 2.081e-05</td> <td> 4.99e-06</td> <td>    4.174</td> <td> 0.000</td> <td>  1.1e-05</td> <td> 3.06e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>balance</th> <td>    0.0056</td> <td>    0.000</td> <td>   24.835</td> <td> 0.000</td> <td>    0.005</td> <td>    0.006</td>\n",
       "</tr>\n",
       "</table><br/><br/>Possibly complete quasi-separation: A fraction 0.14 of observations can be<br/>perfectly predicted. This might indicate that there is complete<br/>quasi-separation. In this case some parameters will not be identified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}   &    default01     & \\textbf{  No. Observations:  } &    10000    \\\\\n",
       "\\textbf{Model:}           &      Logit       & \\textbf{  Df Residuals:      } &     9997    \\\\\n",
       "\\textbf{Method:}          &       MLE        & \\textbf{  Df Model:          } &        2    \\\\\n",
       "\\textbf{Date:}            & Sat, 03 May 2025 & \\textbf{  Pseudo R-squ.:     } &   0.4594    \\\\\n",
       "\\textbf{Time:}            &     18:47:43     & \\textbf{  Log-Likelihood:    } &   -789.48   \\\\\n",
       "\\textbf{converged:}       &       True       & \\textbf{  LL-Null:           } &   -1460.3   \\\\\n",
       "\\textbf{Covariance Type:} &    nonrobust     & \\textbf{  LLR p-value:       } & 4.541e-292  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                 & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{const}   &     -11.5405  &        0.435     &   -26.544  &         0.000        &      -12.393    &      -10.688     \\\\\n",
       "\\textbf{income}  &    2.081e-05  &     4.99e-06     &     4.174  &         0.000        &      1.1e-05    &     3.06e-05     \\\\\n",
       "\\textbf{balance} &       0.0056  &        0.000     &    24.835  &         0.000        &        0.005    &        0.006     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be \\newline\n",
       " perfectly predicted. This might indicate that there is complete \\newline\n",
       " quasi-separation. In this case some parameters will not be identified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:              default01   No. Observations:                10000\n",
       "Model:                          Logit   Df Residuals:                     9997\n",
       "Method:                           MLE   Df Model:                            2\n",
       "Date:                Sat, 03 May 2025   Pseudo R-squ.:                  0.4594\n",
       "Time:                        18:47:43   Log-Likelihood:                -789.48\n",
       "converged:                       True   LL-Null:                       -1460.3\n",
       "Covariance Type:            nonrobust   LLR p-value:                4.541e-292\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const        -11.5405      0.435    -26.544      0.000     -12.393     -10.688\n",
       "income      2.081e-05   4.99e-06      4.174      0.000     1.1e-05    3.06e-05\n",
       "balance        0.0056      0.000     24.835      0.000       0.005       0.006\n",
       "==============================================================================\n",
       "\n",
       "Possibly complete quasi-separation: A fraction 0.14 of observations can be\n",
       "perfectly predicted. This might indicate that there is complete\n",
       "quasi-separation. In this case some parameters will not be identified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# data preprocessing - convert 'default' to 0 (No) and 1 (Yes)\n",
    "default['default01'] = (default['default'] == 'Yes').astype(int)\n",
    "\n",
    "# Define predictors and response\n",
    "X = default[['income', 'balance']]\n",
    "X = sm.add_constant(X)  # add intercept\n",
    "y = default['default01']\n",
    "\n",
    "# Fit logistic regression\n",
    "logit_model = sm.Logit(y, X).fit()\n",
    "\n",
    "# Show model summary\n",
    "logit_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model shows that balance is a strong predictor of default, while income has a weaker (larger coefficient 0.0056 vs 0.00002, higher z-statistic 24.8 vs 4.2), though statistically significant, effect. The model explains nearly half of the deviance (R2 = 0.4594). \n",
    "\n",
    "The warning on quasi-separation suggests caution, as some cases may be too easy to classify perfectly. Not sure what to make of this?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5bi.\n",
    "\n",
    "Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:\n",
    "\n",
    "i. Split the sample set into a training set and a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Define predictors and response\n",
    "X = default[['income', 'balance']]\n",
    "y = default['default01']\n",
    "\n",
    "# train/validation split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5bii.\n",
    "\n",
    "Fit a multiple logistic regression model using only the training observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.079028\n",
      "         Iterations 10\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Add intercept to training and validation sets\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "X_val_sm = sm.add_constant(X_val)\n",
    "\n",
    "# Fit logistic regression\n",
    "logit_model = sm.Logit(y_train, X_train_sm).fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5biii.\n",
    "\n",
    "iii. Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3472    0\n",
      "5095    0\n",
      "9504    0\n",
      "5786    0\n",
      "8758    0\n",
      "       ..\n",
      "1625    1\n",
      "990     0\n",
      "2408    0\n",
      "2568    0\n",
      "5075    0\n",
      "Length: 5000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities for validation set\n",
    "probs = logit_model.predict(X_val_sm)\n",
    "\n",
    "# Classify: default if P(default) > 0.5\n",
    "y_pred = (probs > 0.5).astype(int)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5biv.\n",
    "\n",
    " Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Error: 0.0250\n"
     ]
    }
   ],
   "source": [
    "# misclassification rate\n",
    "val_error = np.mean(y_pred != y_val)\n",
    "print(f\"Validation Set Error: {val_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error rate of 2.5%, model correctly classified 97.5% of validation observations using the 0.5 threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5c.\n",
    "\n",
    "Repeat the process in (b) three times, using three different splits  of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seed 42 - Validation Set Error: 0.0258\n",
      "Seed 43 - Validation Set Error: 0.0282\n",
      "Seed 44 - Validation Set Error: 0.0252\n"
     ]
    }
   ],
   "source": [
    "# Track results\n",
    "errors = []\n",
    "\n",
    "# TODO: Is this question is asking to randomize the observations per split, not the split size???\n",
    "for seed in [42, 43, 44]:\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Train/test split\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        default[['income', 'balance']],\n",
    "        default['default01'],\n",
    "        test_size=0.5,\n",
    "        random_state=seed\n",
    "    )\n",
    "    \n",
    "    # Add intercept\n",
    "    X_train_sm = sm.add_constant(X_train)\n",
    "    X_val_sm = sm.add_constant(X_val)\n",
    "    \n",
    "    # Fit model\n",
    "    model = sm.Logit(y_train, X_train_sm).fit(disp=False)\n",
    "    \n",
    "    # Predict and classify\n",
    "    probs = model.predict(X_val_sm)\n",
    "    preds = (probs > 0.5).astype(int)\n",
    "    \n",
    "    # Compute error\n",
    "    error = np.mean(preds != y_val)\n",
    "    errors.append(error)\n",
    "    print(f\"Seed {seed} - Validation Set Error: {error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relatively stable test error found across different random splits confirms that the model indicating it generalizes well. The small variability in error (within ~0.2%) implies low variance in performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5d.\n",
    "\n",
    "Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a  dummy variable for student leads to a reduction in the test error rate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.077900\n",
      "         Iterations 10\n",
      "Validation Set Error with student dummy var: 0.0256\n"
     ]
    }
   ],
   "source": [
    "# Convert student' to binary dummy variable\n",
    "default['student01'] = (default['student'] == 'Yes').astype(int)\n",
    "\n",
    "# Set seed\n",
    "np.random.seed(42)\n",
    "\n",
    "# define predictors / response\n",
    "X = default[['income', 'balance', 'student01']]\n",
    "y = default['default01']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5, random_state=42)\n",
    "\n",
    "# add intercept\n",
    "X_train_sm = sm.add_constant(X_train)\n",
    "X_val_sm = sm.add_constant(X_val)\n",
    "\n",
    "# Fit model\n",
    "model = sm.Logit(y_train, X_train_sm).fit()\n",
    "\n",
    "# predict and classify\n",
    "probs = model.predict(X_val_sm)\n",
    "preds = (probs > 0.5).astype(int)\n",
    "\n",
    "# Compute test error\n",
    "val_error = np.mean(preds != y_val)\n",
    "print(f\"Validation Set Error with student dummy var: {val_error:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding student dummy variable did not significantly reduce the test error. In fact, the error remained pretty much the same / increased slightly (e.g. 2.50% to 2.56%). This suggests that student provides little additional predictive value beyond what is already captured by balance and income."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6.\n",
    "\n",
    "We continue to consider the use of a logistic regression model to predict the probability of default using income and balance on the\n",
    "Default data set. In particular, we will now compute estimates for the standard errors of the income and balance logistic regression coefficients in two different ways: (1) using the bootstrap, and (2) using the standard formula for computing the standard errors in the `sm.GLM()` function. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6a.\n",
    "\n",
    "Using the summarize() and sm.GLM() functions, determine the estimated standard errors for the coefficients associated with\n",
    "income and balance in a multiple logistic regression model that uses both predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "      <th>std err</th>\n",
       "      <th>z</th>\n",
       "      <th>P&gt;|z|</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>const</th>\n",
       "      <td>-11.540500</td>\n",
       "      <td>0.435000</td>\n",
       "      <td>-26.544</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>income</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>4.174</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>balance</th>\n",
       "      <td>0.005600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>24.835</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              coef   std err       z  P>|z|\n",
       "const   -11.540500  0.435000 -26.544    0.0\n",
       "income    0.000021  0.000005   4.174    0.0\n",
       "balance   0.005600  0.000000  24.835    0.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ISLP import load_data\n",
    "from ISLP.models import summarize\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# load\n",
    "default = load_data('Default')\n",
    "\n",
    "# Convert default to binary response\n",
    "default['default01'] = (default['default'] == 'Yes').astype(int)\n",
    "\n",
    "# define predictors and response\n",
    "X = default[['income', 'balance']]\n",
    "X = sm.add_constant(X)  # add intercept\n",
    "y = default['default01']\n",
    "\n",
    "# Fit logistic regression model binomial / logistic\n",
    "model = sm.GLM(y, X, family=sm.families.Binomial())\n",
    "results = model.fit()\n",
    "\n",
    "# summary\n",
    "summarize(results) # TODO: balance std err 0.0???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6b.\n",
    "\n",
    "Write a function, boot_fn(), that takes as input the Default data  set as well as an index of the observations, and that outputs the coefficient estimates for income and balance in the multiple  logistic regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "def boot_fn(data, index):\n",
    "    \"\"\"\n",
    "    Fit a logistic regression model on a subset of the data defined by `index`,\n",
    "    and returns the estimated coefficients for income and balance.\n",
    "    param: data (DataFrame): The Default dataset.\n",
    "    param: index (array-like): Row indices to include in the sample.\n",
    "    returns: ndarray: Coefficients for [intercept, income, balance].\n",
    "    \"\"\"\n",
    "    # select resampled data\n",
    "    sample = data.iloc[index]\n",
    "    \n",
    "    # Define predictors and response\n",
    "    X = sample[['income', 'balance']]\n",
    "    X = sm.add_constant(X)\n",
    "    y = (sample['default'] == 'Yes').astype(int)\n",
    "    \n",
    "    # fit model\n",
    "    model = sm.Logit(y, X).fit(disp=False)\n",
    "    \n",
    "    return model.params.values  # [intercept, income, balance]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6c.\n",
    "\n",
    "Following the bootstrap example in the lab, use your boot_fn()  function to estimate the standard errors of the logistic regression coefficients for income and balance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap SEs:\n",
      "Income: 5.243875934638313e-06\n",
      "Balance: 0.00023046818518135682\n"
     ]
    }
   ],
   "source": [
    "from ISLP import load_data\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "# reload Default data and convert default to binary\n",
    "default = load_data('Default')\n",
    "default['default01'] = (default['default'] == 'Yes').astype(int)\n",
    "\n",
    "def boot_coeffs(D, idx):\n",
    "    \"\"\"\n",
    "    Returns both income and balance coefficients from logistic regression.\n",
    "    \"\"\"\n",
    "    sample = D.loc[idx]\n",
    "    X = sample[['income', 'balance']]\n",
    "    X = sm.add_constant(X)\n",
    "    y = sample['default01']\n",
    "    model = sm.GLM(y, X, family=sm.families.Binomial()).fit()\n",
    "    return model.params[['income', 'balance']].values  # returns a vector\n",
    "\n",
    "\n",
    "# Run bootstrap func\n",
    "rng = np.random.default_rng(seed=42)\n",
    "B = 100\n",
    "coefs = np.zeros((B, 2))  # 2 for income and balance\n",
    "\n",
    "for b in range(B):\n",
    "    idx = rng.choice(default.index, size=len(default), replace=True)\n",
    "    coefs[b] = boot_coeffs(default, idx)\n",
    "\n",
    "# Compute standard errors\n",
    "bootstrap_se = coefs.std(axis=0)\n",
    "print(f\"Bootstrap SEs:\\nIncome: {bootstrap_se[0]}\\nBalance: {bootstrap_se[1]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6d.\n",
    "\n",
    "Comment on the estimated standard errors obtained using the `sm.GLM()` function and using the bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "balance SE from 6(a) is different, but still small and in agreement with standard formula. Maybe a pandas issue in 6(a)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9.\n",
    "\n",
    "We will now consider the Boston housing data set, from the ISLP library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Boston housing data\n",
    "boston = load_data('Boston')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9a.\n",
    "\n",
    "Based on this data set, provide an estimate for the population mean of medv. Call this estimate µˆ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated population mean of medv: 22.5328\n"
     ]
    }
   ],
   "source": [
    "# Compute the estimate of the population mean\n",
    "mu_hat = boston['medv'].mean()\n",
    "print(f\"Estimated population mean of medv: {mu_hat:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9b.\n",
    "\n",
    "Provide an estimate of the standard error of mu_hat. Interpret this result.\n",
    "Hint: We can compute the standard error of the sample mean by dividing the sample standard deviation by the square root of the number of observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample mean: 22.5328\n",
      "Standard error: 0.4089\n"
     ]
    }
   ],
   "source": [
    "# Number of observations\n",
    "n = boston.shape[0]\n",
    "\n",
    "# Sample standard deviation\n",
    "std_dev = boston['medv'].std(ddof=1)  # use ddof=1 for sample SD???\n",
    "\n",
    "# SE of the mean\n",
    "se_mu = std_dev / np.sqrt(n)\n",
    "\n",
    "print(f\"Sample mean: {mu_hat:.4f}\") # same\n",
    "print(f\"Standard error: {se_mu:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6c.\n",
    "\n",
    "Now estimate the standard error of µˆ using the bootstrap. How does this compare to your answer from (b)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap standard error: 0.4315\n"
     ]
    }
   ],
   "source": [
    "# new bootstrap func\n",
    "def boot_mu(D, idx):\n",
    "    return D['medv'].iloc[idx].mean()\n",
    "\n",
    "# redefine boot_se\n",
    "def boot_SE(func, D, n=None, B=1000, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index, size=n, replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)\n",
    "\n",
    "bootstrap_se = boot_SE(boot_mu, boston, B=100, seed=0)\n",
    "print(f\"Bootstrap standard error: {bootstrap_se:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrap standard error of the sample mean was estimated to be 0.4315, which is slightly higher than the analytical standard error of approximately 0.4089. This small difference suggests that that both methods provide consistent estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9d.\n",
    "\n",
    "Based on your bootstrap estimate from (c), provide a 95 % confidence interval for the mean of medv. Compare it to the results obtained by using Boston['medv'].std() and the two standard error rule (3.9).\n",
    "Hint: You can approximate a 95 % confidence interval using the formula [ˆµ − 2SE(ˆµ), µˆ + 2SE(ˆµ)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95% CI (Bootstrap): [21.6699, 23.3957]\n",
      "95% CI (Analytical): [21.7151, 23.3505]\n"
     ]
    }
   ],
   "source": [
    "## bootstap CI\n",
    "ci_lower = mu_hat - 2 * bootstrap_se\n",
    "ci_upper = mu_hat + 2 * bootstrap_se\n",
    "print(f\"95% CI (Bootstrap): [{ci_lower:.4f}, {ci_upper:.4f}]\")\n",
    "\n",
    "## analytical CI\n",
    "ci_lower_analytical = mu_hat - 2 * se_mu\n",
    "ci_upper_analytical = mu_hat + 2 * se_mu\n",
    "print(f\"95% CI (Analytical): [{ci_lower_analytical:.4f}, {ci_upper_analytical:.4f}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both intervals are very similar, both centered around the sample mean (~22.53), with the bootstrap interval being slightly wider."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9e.\n",
    "\n",
    "Based on this data set, provide an estimate, µˆmed, for the median value of medv in the population."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated population median: 21.2000\n"
     ]
    }
   ],
   "source": [
    "mu_hat_median = boston['medv'].median()\n",
    "print(f\"Estimated population median: {mu_hat_median:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9f.\n",
    "\n",
    "We now would like to estimate the standard error of µˆmed. Unfortunately, there is no simple formula for computing the standard error of the median. Instead, estimate the standard error of the median using the bootstrap. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap standard error of median: 0.3444\n"
     ]
    }
   ],
   "source": [
    "# median bootstrp\n",
    "def boot_median(D, idx):\n",
    "    return D['medv'].iloc[idx].median()\n",
    "\n",
    "# boot SE again\n",
    "def boot_SE(func, D, n=None, B=100, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index, size=n, replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)\n",
    "\n",
    "# Run\n",
    "bootstrap_se_median = boot_SE(boot_median, boston, B=100, seed=0)\n",
    "print(f\"Bootstrap standard error of median: {bootstrap_se_median:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeatedly sampled from the population and calculated the median medv, the typical deviation from the true median would be around 0.34 units. This is slightly lower than the standard error of the mean (~0.41), suggesting that the median is a relatively good estimator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9g.\n",
    "\n",
    "Based on this data set, provide an estimate for the tenth percentile of medv in Boston census tracts. Call this quantity µˆ0.1.\n",
    "(You can use the `np.percentile()` function.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated 10th percentile of medv: 12.7500\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute the 10th percentile\n",
    "mu_hat_0_1 = np.percentile(boston['medv'], 10)\n",
    "print(f\"Estimated 10th percentile of medv: {mu_hat_0_1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9h.\n",
    "\n",
    "Use the bootstrap to estimate the standard error of µˆ0.1. Comment on your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bootstrap standard error of 10th percentile: 0.4894\n"
     ]
    }
   ],
   "source": [
    "# percentile bootstrap\n",
    "def boot_percentile_10(D, idx):\n",
    "    return np.percentile(D['medv'].iloc[idx], 10)\n",
    "\n",
    "\n",
    "# boot SE again\n",
    "def boot_SE(func, D, n=None, B=100, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    first_, second_ = 0, 0\n",
    "    n = n or D.shape[0]\n",
    "\n",
    "    for _ in range(B):\n",
    "        idx = rng.choice(D.index, size=n, replace=True)\n",
    "        value = func(D, idx)\n",
    "        first_ += value\n",
    "        second_ += value**2\n",
    "\n",
    "    return np.sqrt(second_ / B - (first_ / B)**2)\n",
    "\n",
    "# Run\n",
    "bootstrap_se_percentile_10 = boot_SE(boot_percentile_10, boston, B=100, seed=0)\n",
    "print(f\"Bootstrap standard error of 10th percentile: {bootstrap_se_percentile_10:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard error of the 10th percentile is ~0.48 which is significantly worse than median, and only slightly worse than mean standard error."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stats_venv)",
   "language": "python",
   "name": "statistics_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
