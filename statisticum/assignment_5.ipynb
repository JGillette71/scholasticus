{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STA-6543 Assignment 5\n",
    "\n",
    "Jason Gillette"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.\n",
    "\n",
    "For parts (a) through (c), indicate which of i. through iv. is correct.\n",
    "Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2a.\n",
    "\n",
    "The lasso, relative to least squares, is:\n",
    "  \n",
    "    iii. Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.\n",
    "\n",
    "        Lasso works when the benefit of reduced variance outweighs the cost of increased bias. It results in a less flexible model in that it biases the model toward specific variables and thus fits less of the training data in favor of more generalization, ie.e reduced variance. A more general model usually has better prediction accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2b.\n",
    "\n",
    " Repeat (a) for ridge regression relative to least squares.\n",
    "\n",
    "    (iii) Less flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.\n",
    "\n",
    "        Least squares regression places no restrictions on a variable's coefficient to influence fit in the reduction of training error. It is means the model is more flexible as it fits any variety of variables. Ridge regression is less flexible as it penalizes large coefficients that place relatively high influence on the model fit. It increases bias by penalizing variable coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2c.\n",
    "\n",
    "Repeat (a) for non-linear methods relative to least squares.\n",
    "\n",
    "    (i) More flexible and hence will give improved prediction accuracy when its increase in bias is less than its decrease in variance.\n",
    "\n",
    "        Non-linear methods are not bound by a straight line and fit more complex patterns in the data, thus they are more flexible. They typically have less bias because they fit patterns easier, but they could have higher variance because they more easily fit to noise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9.\n",
    "\n",
    "In this exercise, we will predict the number of applications received using the other variables in the College data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype   \n",
      "---  ------       --------------  -----   \n",
      " 0   Private      777 non-null    category\n",
      " 1   Apps         777 non-null    int64   \n",
      " 2   Accept       777 non-null    int64   \n",
      " 3   Enroll       777 non-null    int64   \n",
      " 4   Top10perc    777 non-null    int64   \n",
      " 5   Top25perc    777 non-null    int64   \n",
      " 6   F.Undergrad  777 non-null    int64   \n",
      " 7   P.Undergrad  777 non-null    int64   \n",
      " 8   Outstate     777 non-null    int64   \n",
      " 9   Room.Board   777 non-null    int64   \n",
      " 10  Books        777 non-null    int64   \n",
      " 11  Personal     777 non-null    int64   \n",
      " 12  PhD          777 non-null    int64   \n",
      " 13  Terminal     777 non-null    int64   \n",
      " 14  S.F.Ratio    777 non-null    float64 \n",
      " 15  perc.alumni  777 non-null    int64   \n",
      " 16  Expend       777 non-null    int64   \n",
      " 17  Grad.Rate    777 non-null    int64   \n",
      "dtypes: category(1), float64(1), int64(16)\n",
      "memory usage: 104.2 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Private  Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0     Yes  1660    1232     721         23         52         2885   \n",
       "1     Yes  2186    1924     512         16         29         2683   \n",
       "2     Yes  1428    1097     336         22         50         1036   \n",
       "3     Yes   417     349     137         60         89          510   \n",
       "4     Yes   193     146      55         16         44          249   \n",
       "\n",
       "   P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "2           99     11250        3750    400      1165   53        66   \n",
       "3           63     12960        5450    450       875   92        97   \n",
       "4          869      7560        4120    800      1500   76        72   \n",
       "\n",
       "   S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0       18.1           12    7041         60  \n",
       "1       12.2           16   10527         56  \n",
       "2       12.9           30    8735         54  \n",
       "3        7.7           37   19016         59  \n",
       "4       11.9            2   10922         15  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "\n",
    "# Load College dataset\n",
    "college = load_data('College')\n",
    "\n",
    "# Look at initial structure\n",
    "college.info()\n",
    "college.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 777 entries, 0 to 776\n",
      "Data columns (total 18 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   Private      777 non-null    int8   \n",
      " 1   Apps         777 non-null    int64  \n",
      " 2   Accept       777 non-null    int64  \n",
      " 3   Enroll       777 non-null    int64  \n",
      " 4   Top10perc    777 non-null    int64  \n",
      " 5   Top25perc    777 non-null    int64  \n",
      " 6   F_Undergrad  777 non-null    int64  \n",
      " 7   P_Undergrad  777 non-null    int64  \n",
      " 8   Outstate     777 non-null    int64  \n",
      " 9   Room_Board   777 non-null    int64  \n",
      " 10  Books        777 non-null    int64  \n",
      " 11  Personal     777 non-null    int64  \n",
      " 12  PhD          777 non-null    int64  \n",
      " 13  Terminal     777 non-null    int64  \n",
      " 14  S_F_Ratio    777 non-null    float64\n",
      " 15  perc_alumni  777 non-null    int64  \n",
      " 16  Expend       777 non-null    int64  \n",
      " 17  Grad_Rate    777 non-null    int64  \n",
      "dtypes: float64(1), int64(16), int8(1)\n",
      "memory usage: 104.1 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F_Undergrad</th>\n",
       "      <th>P_Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room_Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S_F_Ratio</th>\n",
       "      <th>perc_alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad_Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Private  Apps  Accept  Enroll  Top10perc  Top25perc  F_Undergrad  \\\n",
       "0        1  1660    1232     721         23         52         2885   \n",
       "1        1  2186    1924     512         16         29         2683   \n",
       "2        1  1428    1097     336         22         50         1036   \n",
       "3        1   417     349     137         60         89          510   \n",
       "4        1   193     146      55         16         44          249   \n",
       "\n",
       "   P_Undergrad  Outstate  Room_Board  Books  Personal  PhD  Terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "2           99     11250        3750    400      1165   53        66   \n",
       "3           63     12960        5450    450       875   92        97   \n",
       "4          869      7560        4120    800      1500   76        72   \n",
       "\n",
       "   S_F_Ratio  perc_alumni  Expend  Grad_Rate  \n",
       "0       18.1           12    7041         60  \n",
       "1       12.2           16   10527         56  \n",
       "2       12.9           30    8735         54  \n",
       "3        7.7           37   19016         59  \n",
       "4       11.9            2   10922         15  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### adding a cleaning step due to all the value errors downstream.\n",
    "\n",
    "# Rename columns to replace '.' with '_' for sml syntax\n",
    "college.columns = [col.replace('.', '_') for col in college.columns]\n",
    "\n",
    "# Convert 'Private' from Yes/No to 1/0 int\n",
    "college['Private'] = college['Private'].cat.codes\n",
    "\n",
    "# Drop any rows with NaNs\n",
    "college = college.dropna()\n",
    "\n",
    "# confirm casting and rename\n",
    "college.info()\n",
    "college.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9a.\n",
    "\n",
    "Split the data set into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (543, 17), Test set: (234, 17)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# set random seed for reproducibility\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Split the College data into features (X) and target (y)\n",
    "X = college.drop(columns='Apps')  # predictors\n",
    "y = college['Apps']               # target: number of applications\n",
    "\n",
    "# Perform train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# sizes\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9b.\n",
    "\n",
    "Fit a linear model using least squares on the training set, and  report the test error obtained. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 1931803.1942\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# join X and y back into single training/test DataFrame\n",
    "train = X_train.copy()\n",
    "train['Apps'] = y_train\n",
    "\n",
    "test = X_test.copy()\n",
    "test['Apps'] = y_test\n",
    "\n",
    "# Fit model\n",
    "# Cite OpenAi o4 here, examples in book caused syntax error.\n",
    "model = smf.ols(\n",
    "    'Apps ~ Private + Accept + Enroll + Top10perc + Top25perc + F_Undergrad + P_Undergrad + Outstate + Room_Board + Books + Personal + PhD + Terminal + S_F_Ratio + perc_alumni + Expend + Grad_Rate',\n",
    "    data=train\n",
    ").fit()\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(test)\n",
    "\n",
    "# Test MSE\n",
    "mse_test = mean_squared_error(test['Apps'], y_pred)\n",
    "print(f\"Test MSE: {mse_test:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9c.\n",
    "\n",
    "Fit a ridge regression model on the training set, with λ chosen by cross-validation. Report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (Ridge): 1931467.5647\n",
      "Optimal lambda (alpha) via CV: 0.0100\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import numpy as np\n",
    "\n",
    "# Ridge requires scaled predictors\n",
    "ridge_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RidgeCV(alphas=10**np.linspace(10, -2, 100), store_cv_results=True)\n",
    ")\n",
    "\n",
    "# Fit ridge on training data\n",
    "ridge_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "# Test MSE\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "print(f\"Test MSE (Ridge): {mse_ridge:.4f}\")\n",
    "\n",
    "# Best lambda chosen\n",
    "best_lambda = ridge_model.named_steps['ridgecv'].alpha_\n",
    "print(f\"Optimal lambda (alpha) via CV: {best_lambda:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ridge regression slightly improved test error by ~335 units, a modest gain, suggesting the least squares model may not be severely overfitting and Ridge Regression helped, but only marginally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9d.\n",
    "\n",
    "Fit a lasso model on the training set, with λ chosen by cross-validation. Report the test error obtained, along with the number of non-zero coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (Lasso): 1931787.4564\n",
      "Optimal lambda (alpha): 0.0100\n",
      "Number of non-zero coefficients: 17\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Lasso model pipeline: standardize then cross-validated lasso\n",
    "lasso_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    LassoCV(alphas=10**np.linspace(10, -2, 100), cv=10, max_iter=10000, random_state=42)\n",
    ")\n",
    "\n",
    "# Fit model on training data\n",
    "lasso_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_lasso = lasso_model.predict(X_test)\n",
    "\n",
    "# Compute test MSE\n",
    "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
    "\n",
    "# Extract best lambda and coefficients\n",
    "lasso_cv = lasso_model.named_steps['lassocv']\n",
    "best_lambda = lasso_cv.alpha_\n",
    "nonzero_coefs = np.sum(lasso_cv.coef_ != 0)\n",
    "\n",
    "print(f\"Test MSE (Lasso): {mse_lasso:.4f}\")\n",
    "print(f\"Optimal lambda (alpha): {best_lambda:.4f}\")\n",
    "print(f\"Number of non-zero coefficients: {nonzero_coefs}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso chose the same number of predictors (17), meaning none were shrunk to zero; suggests all predictors are at least marginally useful. The MSE is slightly better than least squares, but slightly worse than ridge regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9e.\n",
    "\n",
    "Fit a PCR model on the training set, with M chosen by cross-validation. Report the test error obtained, along with the value of M selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of components (M): 17\n",
      "Test MSE (PCR): 1931803.1942\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# total number of features (17)\n",
    "m_values = list(range(1, X_train.shape[1] + 1))\n",
    "cv_errors = []\n",
    "\n",
    "for m in m_values:\n",
    "    # Create PCR pipeline\n",
    "    pcr_pipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('pca', PCA(n_components=m)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ])\n",
    "\n",
    "    # Negative MSE (so higher is better) across 10 folds\n",
    "    scores = cross_val_score(pcr_pipeline, X_train, y_train,\n",
    "                             scoring='neg_mean_squared_error', cv=10)\n",
    "    \n",
    "    # Average MSE (flip sign)\n",
    "    cv_errors.append(-scores.mean())\n",
    "\n",
    "# Get best M\n",
    "best_m = m_values[np.argmin(cv_errors)]\n",
    "print(f\"Best number of components (M): {best_m}\")\n",
    "\n",
    "# Final PCR model with best M\n",
    "final_pcr = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA(n_components=best_m)),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "\n",
    "final_pcr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_pcr = final_pcr.predict(X_test)\n",
    "\n",
    "# Test MSE\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse_pcr = mean_squared_error(y_test, y_pred_pcr)\n",
    "print(f\"Test MSE (PCR): {mse_pcr:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact same test MSE as standard least squares... suggesting all variables are uniquely contributing and consistent with other model results?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9f.\n",
    "\n",
    "Fit a PLS model on the training set, with M chosen by cross-validation. Report the test error obtained, along with the value of M selected by cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of components (M): 14\n",
      "Test MSE (PLS): 1930317.7199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "m_values = list(range(1, X_train.shape[1] + 1))  # Try 1 to 17 components\n",
    "cv_errors = []\n",
    "\n",
    "for m in m_values:\n",
    "    # Build PLS pipeline\n",
    "    pls_pipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('pls', PLSRegression(n_components=m))\n",
    "    ])\n",
    "\n",
    "    # Use negative MSE scoring, average over 10-fold CV\n",
    "    scores = cross_val_score(pls_pipeline, X_train, y_train,\n",
    "                             scoring='neg_mean_squared_error', cv=10)\n",
    "    \n",
    "    cv_errors.append(-scores.mean())  # Flip sign for MSE\n",
    "\n",
    "# Best number of components\n",
    "best_m = m_values[np.argmin(cv_errors)]\n",
    "print(f\"Best number of components (M): {best_m}\")\n",
    "\n",
    "# Final PLS model with best M\n",
    "final_pls = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pls', PLSRegression(n_components=best_m))\n",
    "])\n",
    "\n",
    "final_pls.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred_pls = final_pls.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "mse_pls = mean_squared_error(y_test, y_pred_pls)\n",
    "print(f\"Test MSE (PLS): {mse_pls:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PLS performed best among all models so far, reducing test MSE by about 1,485. It only 14 used components meaning it eliminated 3 components that added noise rather than predictive signal. Since it uses y during component extraction, it focused only on signal relevant to prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9g.\n",
    "\n",
    "Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much  difference among the test errors resulting from these five approaches?\n",
    "\n",
    "| Model | Test MSE | Comments |\n",
    "|-------|----------|----------|\n",
    "| Linear (OLS) | 1,931,803.19 | Baseline |\n",
    "| Ridge (CV) | 1,931,467.56 | Slight improvement |\n",
    "| Lasso (CV) | 1,931,787.46 | No real feature selection |\n",
    "| PCR (CV) | 1,931,803.19 | Identical to OLS (M=17) |\n",
    "| PLS (CV) | 1,930,317.72 | Best, using 14 components |\n",
    "\n",
    "The differences in test error are minimal, less than 0.1% between worst and best models. This suggests all 17 predictors are contributing at least modestly and regularization and dimensionality reduction helped only slightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11.\n",
    "\n",
    "We will now try to predict per capita crime rate in the Boston dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 506 entries, 0 to 505\n",
      "Data columns (total 13 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   crim     506 non-null    float64\n",
      " 1   zn       506 non-null    float64\n",
      " 2   indus    506 non-null    float64\n",
      " 3   chas     506 non-null    int64  \n",
      " 4   nox      506 non-null    float64\n",
      " 5   rm       506 non-null    float64\n",
      " 6   age      506 non-null    float64\n",
      " 7   dis      506 non-null    float64\n",
      " 8   rad      506 non-null    int64  \n",
      " 9   tax      506 non-null    int64  \n",
      " 10  ptratio  506 non-null    float64\n",
      " 11  lstat    506 non-null    float64\n",
      " 12  medv     506 non-null    float64\n",
      "dtypes: float64(10), int64(3)\n",
      "memory usage: 51.5 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242     17.8   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "\n",
       "   lstat  medv  \n",
       "0   4.98  24.0  \n",
       "1   9.14  21.6  \n",
       "2   4.03  34.7  \n",
       "3   2.94  33.4  \n",
       "4   5.33  36.2  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ISLP import load_data\n",
    "import pandas as pd\n",
    "\n",
    "# Load the Boston dataset\n",
    "boston = load_data('Boston')\n",
    "\n",
    "# Preview the data\n",
    "boston.info()\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11a.\n",
    "\n",
    "Try out some of the regression methods explored in this chapter, such as best subset selection, the lasso, ridge regression, and PCR. Present and discuss results for the approaches that you consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE (Least Squares): 50.5105\n",
      "\n",
      "Test MSE (Ridge): 50.3006\n",
      "Optimal lambda (Ridge): 4.6416\n",
      "\n",
      "Best number of components (PLS): 9\n",
      "Test MSE (PLS): 50.5177\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Define predictors and response\n",
    "X = boston.drop(columns='crim')\n",
    "y = boston['crim']\n",
    "\n",
    "# Train-test split (70/30)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1\n",
    ")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Fit and predict least squares\n",
    "lm = LinearRegression()\n",
    "lm.fit(X_train, y_train)\n",
    "y_pred_lm = lm.predict(X_test)\n",
    "\n",
    "# Evaluate least squares\n",
    "mse_lm = mean_squared_error(y_test, y_pred_lm)\n",
    "print(f\"Test MSE (Least Squares): {mse_lm:.4f}\")\n",
    "\n",
    "# try ridge regression\n",
    "ridge_model = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RidgeCV(alphas=10**np.linspace(10, -2, 100), store_cv_results=True)\n",
    ")\n",
    "\n",
    "ridge_model.fit(X_train, y_train)\n",
    "y_pred_ridge = ridge_model.predict(X_test)\n",
    "\n",
    "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
    "best_lambda_ridge = ridge_model.named_steps['ridgecv'].alpha_\n",
    "\n",
    "print(f\"\\nTest MSE (Ridge): {mse_ridge:.4f}\")\n",
    "print(f\"Optimal lambda (Ridge): {best_lambda_ridge:.4f}\")\n",
    "\n",
    "\n",
    "# Try PLS\n",
    "m_values = list(range(1, X_train.shape[1] + 1))\n",
    "cv_errors = []\n",
    "\n",
    "for m in m_values:\n",
    "    pls_pipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('pls', PLSRegression(n_components=m))\n",
    "    ])\n",
    "    scores = cross_val_score(pls_pipeline, X_train, y_train,\n",
    "                             scoring='neg_mean_squared_error', cv=10)\n",
    "    cv_errors.append(-scores.mean())\n",
    "\n",
    "# Choose best M\n",
    "best_m = m_values[np.argmin(cv_errors)]\n",
    "print(f\"\\nBest number of components (PLS): {best_m}\")\n",
    "\n",
    "# Fit final model\n",
    "final_pls = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pls', PLSRegression(n_components=best_m))\n",
    "])\n",
    "final_pls.fit(X_train, y_train)\n",
    "y_pred_pls = final_pls.predict(X_test)\n",
    "mse_pls = mean_squared_error(y_test, y_pred_pls)\n",
    "\n",
    "print(f\"Test MSE (PLS): {mse_pls:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All three models predict per capita crime rate with similar accuracy. Ridge performed marginally better, suggesting that slight coefficient limiting helps stabilize the model. PLS didn’t outperform despite reducing dimensionality, likely because most predictors carry some useful signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11b.\n",
    "\n",
    "Propose a model (or set of models) that seem to perform well on  this data set, and justify your answer. Make sure that you are  evaluating model performance using validation set error, cross-validation, or some other reasonable alternative, as opposed to  using training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best number of components (PCR): 12\n",
      "Test MSE (PCR): 50.5105\n"
     ]
    }
   ],
   "source": [
    "# Let's propose PCR and if poor performance, we'll go with ridge regression\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "m_values = list(range(1, X_train.shape[1] + 1))  # Try 1 to 13 components\n",
    "cv_errors = []\n",
    "\n",
    "for m in m_values:\n",
    "    pcr_pipeline = Pipeline([\n",
    "        ('scale', StandardScaler()),\n",
    "        ('pca', PCA(n_components=m)),\n",
    "        ('linreg', LinearRegression())\n",
    "    ])\n",
    "    \n",
    "    scores = cross_val_score(pcr_pipeline, X_train, y_train,\n",
    "                             scoring='neg_mean_squared_error', cv=10)\n",
    "    cv_errors.append(-scores.mean())\n",
    "\n",
    "best_m = m_values[np.argmin(cv_errors)]\n",
    "print(f\"Best number of components (PCR): {best_m}\")\n",
    "\n",
    "# Final model with best M\n",
    "final_pcr = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('pca', PCA(n_components=best_m)),\n",
    "    ('linreg', LinearRegression())\n",
    "])\n",
    "\n",
    "final_pcr.fit(X_train, y_train)\n",
    "y_pred_pcr = final_pcr.predict(X_test)\n",
    "mse_pcr = mean_squared_error(y_test, y_pred_pcr)\n",
    "\n",
    "print(f\"Test MSE (PCR): {mse_pcr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though PCR used one fewer component than the full 13, the last principal component (PC13) must have contributed very little predictive value, so the regression performance was effectively the same as OLS with all 13 original predictors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Proposed Model is Ridge Regression\n",
    "\n",
    "Among the regression approaches tested, ridge regression produced the lowest test mean squared error (MSE), making it the strongest candidate for modeling per capita crime rate in the Boston dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11c.\n",
    "\n",
    "Does your chosen model involve all of the features in the dataset? Why or why not?\n",
    "\n",
    "Ridge regression includes all features in the model. While it penalizes large coefficients via regularization, it does not eliminate predictors altogether like other methods such as lasso. This is useful when all features are believed to carry some predictive information, which seems to be the case here."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stats_venv)",
   "language": "python",
   "name": "statistics_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
